{
    "header": {
        "brand": "BRAND",
        "about": "ABOUT",
        "works": "WORKS",
        "transmissions": "TRANSMISSIONS",
        "talk_to_us": "TALK TO US"
    },
    "hero": {
        "title": "FROM SET TO SERVER.",
        "subtitle": "10 YEARS OF CRAFT.",
        "scramble": "NOW GENERATIVE.",
        "description": "A NEW DIVISION BY BRICK.\nFROM ZERO TO ALL SINCE 2016."
    },
    "philosophy": {
        "belief_label": "The Belief",
        "raw": {
            "title": "RAW.",
            "text": "AI creates infinite pixels and patterns. But it cannot create intent. It is just a resource."
        },
        "noise": {
            "title": "NOISE.",
            "text": "Without a human hand, generative models are just mathematical coincidence. We provide the vision."
        },
        "direct": {
            "title": "WE DIRECT THE INTELLIGENCE.",
            "text": "The machine is the brush. The database is the paint. We are still the artists."
        }
    },
    "works": {
        "inheritance": {
            "title": "INHERITANCE",
            "subtitle": "SHORT FILM",
            "desc": "Official Selection Gramado Film Festival 2025.",
            "longDesc": "One of the first AI-made films to be selected and exhibited at the Gramado Film Festival. Inheritance tells the story of a civilization that inherits an abandoned world — and repeats, step by step, all the mistakes of its predecessors. A fable about cycles, hubris, and the illusion of progress. The 5-minute version premiered at Gramado; an extended 10-minute version remains unreleased."
        },
        "shift": {
            "title": "WE CAN SELL ANYTHING",
            "subtitle": "MANIFESTO",
            "desc": "Genero Challenge Finalist.",
            "longDesc": "One character. Infinite worlds. In this manifesto, the same man appears in a fashion studio, leads a marching band in a packed stadium, strolls through European palaces, relaxes in a typical American living room, and faces sumo wrestlers — all in 60 seconds. The message is simple: there are no more production limits. Any scenario, any context, any story. Genero Challenge Finalist."
        },
        "anima": {
            "title": "AUTOBOL",
            "subtitle": "REIMAGINED HISTORY",
            "desc": "Bringing back a forgotten sport from the 70s.",
            "longDesc": "Autobol was real. In the 1970s, in Rio de Janeiro, cars pushed a giant ball in matches between Flamengo, Fluminense, Vasco, and Botafogo. Created by doctor Mário Marques Tourinho, the sport was a brief phenomenon and is now almost forgotten. This project reimagines Autobol as it could have been filmed back then — with all the texture, grain, and atmosphere of lost 70s footage."
        },
        "void": {
            "title": "VOID GAZING",
            "subtitle": "DATA VISUALIZATION",
            "desc": "Translating cosmic radiation into visible spectrums.",
            "longDesc": "A data-driven installation that visualizes real-time cosmic radiation data via the NASA Open API. We wrote Python scripts to parse numerical noise into fluid dynamics parameters within TouchDesigner. The AI then textures this simulation in real-time, effectively allowing the audience to 'see' the invisible universe through a human-curated aesthetic lens."
        },
        "urban": {
            "title": "URBAN REEF",
            "subtitle": "PROCEDURAL ENV",
            "desc": "Growing cities like coral. Biological algorithms applied.",
            "longDesc": "Urban Reef explores bio-mimicry in architecture. Using differential growth algorithms in Houdini, we 'grew' city structures that seek light like coral. These procedural meshes were then texturized using AI upscaling, creating a vision of a city that feels grown rather than built, challenging traditional architectural design processes."
        },
        "factory": {
            "title": "FACTORY",
            "subtitle": "RETRO-FUTURISM",
            "desc": "Industrial decay with a retro-futuristic vision.",
            "longDesc": "A factory that never existed, but feels remembered. Factory combines industrial decay with a retro-futuristic aesthetic — as if a future imagined in the 70s had aged and been abandoned. Rust, concrete, silent machinery. A space between the nostalgia of a past and the ruins of a future that never came."
        },
        "dogday": {
            "title": "DOG DAY AFTERNOON",
            "subtitle": "ABSURDIST COMEDY",
            "desc": "Dogs in human situations.",
            "longDesc": "A canine support group with a 'SIT STAY HEAL' banner. A chihuahua in a sweater on a Zoom call. Dog Day Afternoon is absurdist comedy played straight — dogs in everyday human situations, filmed with the sobriety of an indie drama. The title is a reference to Sidney Lumet's classic with Al Pacino."
        }
    },
    "transmissions": {
        "log_001": {
            "title": "THE LATENT SPACE IS A LOCATION",
            "excerpt": "Why we stopped scouting physical ruins and started training LoRAs on brutalist blueprints.",
            "content_p1": "We tend to think of generative models as engines of creation. Input prompt, output image. A linear manufacturing process. But this metaphor is insufficient for high-end production. At Brick, we treat the model not as a factory, but as a territory.",
            "section_title": "The Topography of Noise",
            "content_p2": "Stable Diffusion XL does not \"draw\". It denoises. It subtracts chaos to reveal order. This implies that the image already exists within the high-dimensional noise, mathematically waiting to be uncovered.",
            "quote": "\"We do not build the set. We navigate to the coordinates where the set is statistically most likely to exist.\""
        },
        "log_002": {
            "title": "MOTION VECTORS IN STYLE TRANSFER",
            "excerpt": "Solving the flickering problem in diffusion models. How we use optical flow to enforce temporal consistency.",
            "content_p1": "The jitter. The flicker. The \"boiling\" texture. This is the hallmark of raw AI video. It reveals the frame-by-frame independence of the diffusion process. For <0>Project: Anima</0>, this artifact was unacceptable.",
            "content_p2": "Our solution involved extracting optical flow maps from the source footage using Nuke. These motion vectors act as a temporal skeleton."
        },
        "log_003": {
            "title": "INTENTIONAL GLITCH: THE HUMAN SIGNATURE",
            "excerpt": "When perfection is the error. Injecting noise back into the clean output of commercial models to reclaim the 'cinema' feel.",
            "content_p1": "Modern models are converging towards a \"mid-journey mean\". A polished, plastic aesthetic that screams \"synthetic\". Paradoxically, to make AI imagery feel real, we must break it.",
            "quote": "The artifact is the art."
        }
    },
    "common": {
        "return_surface": "RETURN TO SURFACE",
        "return_index": "RETURN TO INDEX",
        "system_status": "SYSTEM_STATUS",
        "online": "ONLINE",
        "secure_connection": "SECURE CONNECTION",
        "loading": "LOADING SYSTEM..."
    },
    "legacy": {
        "title": "BACKED BY BRICK.",
        "title_mobile_br": "BACKED <br /> BY BRICK.",
        "text": "This isn't a beta test. This is a new lens from a production house with 10 years of experience.",
        "trusted_by": "Trusted By"
    },
    "footer": {
        "complex_problem": "Have a complex problem?",
        "we_have_intelligence": "WE HAVE THE INTELLIGENCE.",
        "talk_to_us": "TALK TO US",
        "network": "Network",
        "rights_reserved": "All Rights Reserved.",
        "generative_division": "The Generative Division",
        "system_admin": "SYSTEM_ADMIN"
    },
    "about": {
        "origin": "SYSTEM_ORIGIN",
        "est": "EST. 2016",
        "title_primary": "FORGED IN",
        "title_highlight": "OLD SCHOOL",
        "title_secondary": "VFX.",
        "description": "Before we ever wrote a prompt, we spent 7 years pushing pixels in Nuke and Maya. We understand light, composition, and storytelling because we built them by hand for a decade. We didn't adopt AI to replace the craft. We adopted it to break the speed limit.",
        "core_modules": "CORE_MODULES",
        "modules": {
            "cinematography": {
                "title": "SYNTHETIC_CINEMATOGRAPHY",
                "status": "INSTALLED",
                "desc": "Video Generation // ComfyUI // 4K Upscaling"
            },
            "training": {
                "title": "MODEL_TRAINING",
                "status": "INSTALLED",
                "desc": "Custom LoRAs // Style Consistency // Fine-Tuning"
            },
            "architecture": {
                "title": "PIPELINE_ARCHITECTURE",
                "status": "INSTALLED",
                "desc": "Python Tooling // Automation // Render Farm"
            }
        },
        "manifesto": {
            "title": "THE ANTI-PROMPT MANIFESTO",
            "subtitle": "Why Magic Doesn't Scale",
            "cards": {
                "control": {
                    "title": "CONTROL > CHANCE",
                    "desc": "The 'perfect prompt' is a myth. Consistency comes from ControlNet, IP-Adapters, and Python scripts, not lucky words. We engineer our images; we don't wish for them."
                },
                "curation": {
                    "title": "CURATION IS CREATION",
                    "desc": "A model can generate 1,000 images in a minute. The art is knowing which one is wrong. Our directors curate with the same critical eye they used on film sets for 10 years."
                },
                "black_box": {
                    "title": "NO BLACK BOXES",
                    "desc": "We don't rely on closed web-interfaces. We build our own ComfyUI pipelines locally. This gives us pixel-level control over the latent space that 'magic buttons' can't provide."
                }
            }
        },
        "team": {
            "title": "UNIT_LEADERS // COMMAND",
            "roles": {
                "alex": "EXECUTIVE PRODUCER",
                "sarah": "CREATIVE DIRECTOR",
                "gabriel": "HEAD OF TECHNOLOGY",
                "marcus": "VFX SUPERVISOR"
            }
        }
    },
    "chat": {
        "reach_humans": "REACH_HUMANS",
        "manual_override": "MANUAL OVERRIDE PROTOCOLS",
        "status_online": "STATUS: ONLINE",
        "email_streams": "EMAIL_STREAMS",
        "voice_link": "VOICE_LINK",
        "network_nodes": "NETWORK_NODES",
        "mason_intro": "I AM MASON",
        "generative_core": "The Generative Core.",
        "state": "State:",
        "active": "ACTIVE",
        "idle": "IDLE",
        "placeholder": "ENTER COMMAND...",
        "execute": "EXECUTE",
        "initial_messages": {
            "online": "SYSTEM_ONLINE. I am MASON. I build the foundation of your reality.",
            "protocol": "Protocol initiated. Transmit your query for immediate processing."
        },
        "suggestions": {
            "philosophy": "What is the Monolith philosophy?",
            "audit": "Execute project audit.",
            "synthesis": "Initiate creative synthesis.",
            "humans": "Manual override: Speak to humans."
        }
    },
    "works_page": {
        "title": "PROJECT_DATABASE // Selected Works",
        "archive_index": "ARCHIVE_INDEX",
        "accessing": "ACESSING NEURAL DATABASE...",
        "entries_found": "ENTRIES FOUND.",
        "no_data": "NO DATA FOUND IN THIS SECTOR.",
        "protocols": "PROTOCOLS"
    },
    "transmissions_page": {
        "title": "NEURAL_LOGS",
        "incoming": "INCOMING DATA STREAMS...",
        "records": "RECORDS."
    },
    "project_modal": {
        "neural_active": "NEURAL_RENDER_ACTIVE",
        "static_preview": "STATIC_PREVIEW",
        "system_data": "System Data"
    }
}